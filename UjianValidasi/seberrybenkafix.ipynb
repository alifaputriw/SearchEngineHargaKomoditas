{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "https://berrybenka.com/clothing/bottoms/jeans/brand/emba-jeans--carvil/men?popular=desc\n",
      "0\n",
      "https://berrybenka.com/clothing/bottoms/long-pants/brand/Third-Day--Emba-Classic/men?popular=desc\n",
      "0\n",
      "https://berrybenka.com/clothing/bottoms/short-pants/brand/carvil--Minarno/men?popular=desc\n",
      "0\n",
      "https://berrybenka.com/clothing/outerwear/jackets/brand/rown-division--crows-denims/men?popular=desc\n",
      "0\n",
      "https://berrybenka.com/clothing/batik/brand/batik-arthesian--Arjuna-Weda/men?popular=desc\n",
      "0\n",
      "https://berrybenka.com/clothing/tops/men-shirt/brand/A-and-D--greenlight-men/men?popular=desc\n",
      "0\n",
      "https://berrybenka.com/clothing/batik/brand/batik-arthesian--Arjuna-Weda/men?popular=desc\n",
      "0\n",
      "https://berrybenka.com/clothing/tops/men-shirt/brand/A-and-D--greenlight-men/men?popular=desc\n",
      "0\n",
      "https://berrybenka.com/shoes/sandals/brand/drkevin--carvil/men?popular=desc\n",
      "0\n",
      "https://berrybenka.com/shoes/sandals/brand/carvil--Yongki-Komaladi/men?popular=desc\n",
      "0\n",
      "https://berrybenka.com/shoes/formal-shoes/brand/drkevin--Yongki-Komaladi/men?popular=desc\n",
      "0\n",
      "https://berrybenka.com/tops/baju-koko/brand/carvil/men?popular=desc\n",
      "0\n",
      "https://berrybenka.com/tops/women-tees/brand/3-second--x8/women?popular=desc\n",
      "0\n",
      "https://berrybenka.com/clothing/pakaian-tidur/nightwear/brand/puppy--Madeleine/women?popular=desc\n",
      "0\n",
      "https://berrybenka.com/clothing/batik/brand/Anakara--Bhatara-Batik/women?popular=desc\n",
      "0\n",
      "https://berrybenka.com/clothing/tops/blouse/brand/white-mode--point-one/women?popular=desc\n",
      "0\n",
      "https://berrybenka.com/clothing/bottoms/jeans/brand/lois-girl--carvil/women?popular=desc\n",
      "0\n",
      "https://berrybenka.com/clothing/dresses/jumpsuit/brand/MKY-Clothing--aston-fashion/women?popular=desc\n",
      "4\n",
      "https://berrybenka.com/accessories/socks/women?popular=desc\n",
      "https://berrybenka.com/accessories/socks/women/48?popular=desc\n",
      "https://berrybenka.com/accessories/socks/women/96?popular=desc\n",
      "https://berrybenka.com/accessories/socks/women/144?popular=desc\n",
      "0\n",
      "https://berrybenka.com/bottoms/skirts/brand/white-mode--MKY-Clothing/women?popular=desc\n",
      "0\n",
      "https://berrybenka.com/bottoms/short-pants/brand/point-one--beyounique/women?popular=desc\n",
      "0\n",
      "https://berrybenka.com/bottoms/leggings/brand/nike--point-one/women?popular=desc\n",
      "0\n",
      "https://berrybenka.com/accessories/wallet-cases/brand/eagle-leather-goods--lutece/men?popular=desc\n",
      "3\n",
      "https://berrybenka.com/bags/handbag/brand/gykaco--coup-belle/women?popular=desc\n",
      "https://berrybenka.com/bags/handbag/brand/gykaco--coup-belle/women/48?popular=desc\n",
      "https://berrybenka.com/bags/handbag/brand/gykaco--coup-belle/women/96?popular=desc\n",
      "0\n",
      "https://berrybenka.com/accessories/hats/brand/Cottonology--adidas/men?popular=desc\n",
      "0\n",
      "https://berrybenka.com/bags/backpack/brand/rown-division--polo-regio/men?popular=desc\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "9 columns passed, passed data had 8 columns",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-f6e55b2ffdb3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    198\u001b[0m     \u001b[0mnow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'berrybenka_%s_%s_%s %s_%s_%s_%s.csv'\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mday\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmonth\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0myear\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhour\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mminute\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msecond\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmicrosecond\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 200\u001b[1;33m     \u001b[0mdf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mberrybenka_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'linkEcommerce'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'kategoriProduk'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'namaProduk'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'brandProduk'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'hargaBaru'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'hargaLama'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'diskonProduk'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'linkProduk'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'tgl update'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    201\u001b[0m     \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    312\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mis_named_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m                         \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fields\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 314\u001b[1;33m                     \u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_to_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    315\u001b[0m                     \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_ensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_to_arrays\u001b[1;34m(data, columns, coerce_float, dtype)\u001b[0m\n\u001b[0;32m   5615\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5616\u001b[0m         return _list_to_arrays(data, columns, coerce_float=coerce_float,\n\u001b[1;32m-> 5617\u001b[1;33m                                dtype=dtype)\n\u001b[0m\u001b[0;32m   5618\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMapping\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5619\u001b[0m         return _list_of_dict_to_arrays(data, columns,\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_list_to_arrays\u001b[1;34m(data, columns, coerce_float, dtype)\u001b[0m\n\u001b[0;32m   5694\u001b[0m         \u001b[0mcontent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_object_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5695\u001b[0m     return _convert_object_array(content, columns, dtype=dtype,\n\u001b[1;32m-> 5696\u001b[1;33m                                  coerce_float=coerce_float)\n\u001b[0m\u001b[0;32m   5697\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5698\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_convert_object_array\u001b[1;34m(content, columns, coerce_float, dtype)\u001b[0m\n\u001b[0;32m   5753\u001b[0m             \u001b[1;31m# caller's responsibility to check for this...\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5754\u001b[0m             raise AssertionError('%d columns passed, passed data had %s '\n\u001b[1;32m-> 5755\u001b[1;33m                                  'columns' % (len(columns), len(content)))\n\u001b[0m\u001b[0;32m   5756\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5757\u001b[0m     \u001b[1;31m# provide soft conversion of object dtypes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: 9 columns passed, passed data had 8 columns"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import urllib.request\n",
    "import csv\n",
    "from urllib.request import urlopen\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "with open ('F:\\\\SKRIPSI\\\\Topik2\\\\UjianValidasi\\\\LinkURL\\\\url_berrybenka.csv') as f:\n",
    "    urls=(line.strip()for line in f)\n",
    "    berrybenka_list= []\n",
    "    for row in urls:\n",
    "        r = urlopen(row)\n",
    "        soup = BeautifulSoup(r, \"html.parser\")\n",
    "        \n",
    "        page= soup.find(id=\"ul-pagination\")\n",
    "        list_page= page.find_all('a')\n",
    "        total_page = len(list_page)\n",
    "        print(total_page)\n",
    "        \n",
    "        all_product= soup.find_all(id=\"li-catalog\")\n",
    "        next_product=[]\n",
    "        if total_page == 0:\n",
    "            print(row)\n",
    "            \n",
    "            for item in all_product :\n",
    "                try:\n",
    "                    linkEcommerce = row\n",
    "                except :\n",
    "                    linkEcommerce = ''\n",
    "                try:\n",
    "                    namaProduk=item.find_all('div', {\"class\":\"detail-left\"})[0].text\n",
    "                    namaProduk=namaProduk.find_all('h1')[0].text\n",
    "                            \n",
    "                except:\n",
    "                    namaProduk=''\n",
    "                        \n",
    "                try:\n",
    "                    diskonProduk=item.find_all('div', {\"class\":\"detail-left\"})[0].text\n",
    "                    diskonProduk=diskonProduk.find_all('p')[0].text\n",
    "                    diskonProduk= diskonProduk.replace('% off','')\n",
    "                    diskonProduk= int(diskonProduk)/100\n",
    "                except:\n",
    "                    diskonProduk=''\n",
    "                try:\n",
    "                    hargaLama=item.find_all('div', {\"class\":\"detail-right\"})[0].text\n",
    "                    hargaLama=hargaLama.find_all('p')[0].text\n",
    "                    hargaLama = hargaLama.replace('IDR ','')\n",
    "                    hargaLama = hargaLama.replace('.','')\n",
    "                except:\n",
    "                    hargaLama =\"\"\n",
    "                try:\n",
    "                    hargaBaru= item.find_all('div', {\"class\":\"detail-right\"})[0].text\n",
    "                    hargaBaru=hargaBaru.find_all('p', {\"class\":\"detail-right\"})[0].text\n",
    "                    hargaBaru = hargaBaru.replace('IDR ','')\n",
    "                    hargaBaru = hargaBaru.replace('.','')\n",
    "                except:\n",
    "                    hargaBaru= \"\"\n",
    "                        \n",
    "                try:\n",
    "                    wil_url_produk=item.find_all('a')[0]\n",
    "                    linkProduk=wil_url_produk.get('href')\n",
    "                except:\n",
    "                    linkProduk=''\n",
    "                try:\n",
    "                    u= urlopen(linkProduk)\n",
    "                    url_produk_soup = BeautifulSoup(u, \"html.parser\")\n",
    "                    kat= url_produk_soup.find('div', {\"class\":\"detail-wrapper\"})\n",
    "                    kategori= kat.find_all('a')[0].text\n",
    "                            \n",
    "                except:\n",
    "                    kategori= ''\n",
    "\n",
    "                berrybenka=[linkEcommerce,kategori,namaProduk,hargaBaru,hargaLama,diskonProduk,linkProduk, datetime.now().strftime(\"%y-%m-%d %H:%M\")]\n",
    "                berrybenka_list.append(berrybenka)\n",
    "            \n",
    "        else:                            \n",
    "            for i in range(total_page):\n",
    "                if i == 0:\n",
    "                    print(row)\n",
    "                    r = urlopen(row)\n",
    "                    soup = BeautifulSoup(r, \"html.parser\")\n",
    "        \n",
    "                    page= soup.find(id=\"ul-pagination\")\n",
    "                    all_product= soup.find_all(id=\"li-catalog\")\n",
    "                    for item in all_product :\n",
    "                        try:\n",
    "                            linkEcommerce = row\n",
    "                        except :\n",
    "                            linkEcommerce = ''\n",
    "                        try:\n",
    "                            namaProduk=item.find_all('div', {\"class\":\"detail-left\"})[0].text\n",
    "                            namaProduk=namaProduk.find_all('h1')[0].text\n",
    "                            \n",
    "                        except:\n",
    "                            namaProduk=''\n",
    "                        \n",
    "                        try:\n",
    "                            diskonProduk=item.find_all('div', {\"class\":\"detail-left\"})[0].text\n",
    "                            diskonProduk=diskonProduk.find_all('p')[0].text\n",
    "                            diskonProduk= diskonProduk.replace('% off','')\n",
    "                            diskonProduk= int(diskonProduk)/100\n",
    "                        except:\n",
    "                            diskonProduk=''\n",
    "                        try:\n",
    "                            hargaLama=item.find_all('div', {\"class\":\"detail-right\"})[0].text\n",
    "                            hargaLama=hargaLama.find_all('p')[0].text\n",
    "                            hargaLama = hargaLama.replace('IDR ','')\n",
    "                            hargaLama = hargaLama.replace('.','')\n",
    "                        except:\n",
    "                            hargaLama =\"\"\n",
    "                        try:\n",
    "                            hargaBaru= item.find_all('div', {\"class\":\"detail-right\"})[0].text\n",
    "                            hargaBaru=hargaBaru.find_all('p', {\"class\":\"detail-right\"})[0].text\n",
    "                            hargaBaru = hargaBaru.replace('IDR ','')\n",
    "                            hargaBaru = hargaBaru.replace('.','')\n",
    "                        except:\n",
    "                            hargaBaru= \"\"\n",
    "                        \n",
    "                        try:\n",
    "                            wil_url_produk=item.find_all('a')[0]\n",
    "                            linkProduk=wil_url_produk.get('href')\n",
    "                        except:\n",
    "                            linkProduk=''\n",
    "                        try:\n",
    "                            u= urlopen(linkProduk)\n",
    "                            url_produk_soup = BeautifulSoup(u, \"html.parser\")\n",
    "                            kat= url_produk_soup.find('div', {\"class\":\"detail-wrapper\"})\n",
    "                            kategori= kat.find_all('a')[0].text\n",
    "                            \n",
    "                        except:\n",
    "                            kategoriProduk= ''\n",
    "\n",
    "                        berrybenka=[linkEcommerce,kategori,namaProduk,hargaBaru,hargaLama,diskonProduk,linkProduk, datetime.now().strftime(\"%y-%m-%d %H:%M\")]\n",
    "                        berrybenka_list.append(berrybenka)\n",
    "                        \n",
    "                else:\n",
    "                    change_url= row.replace('?popular=desc','/%s?popular=desc'%(i*48))\n",
    "                    print(change_url)\n",
    "                    c= urlopen(change_url)\n",
    "                    next_soup = BeautifulSoup(c, \"html.parser\")\n",
    "                    next_product= next_soup.find_all(id=\"li-catalog\")\n",
    "            \n",
    "                    for item in all_product :\n",
    "                        try:\n",
    "                            linkEcommerce = row\n",
    "                        except :\n",
    "                            linkEcommerce = ''\n",
    "                        try:\n",
    "                            namaProduk=item.find_all('div', {\"class\":\"detail-left\"})[0].text\n",
    "                            namaProduk=namaProduk.find_all('h1')[0].text\n",
    "                            \n",
    "                        except:\n",
    "                            namaProduk=''\n",
    "                        \n",
    "                        try:\n",
    "                            diskonProduk=item.find_all('div', {\"class\":\"detail-left\"})[0].text\n",
    "                            diskonProduk=diskonProduk.find_all('p')[0].text\n",
    "                            diskonProduk= diskonProduk.replace('% off','')\n",
    "                            diskonProduk= int(diskonProduk)/100\n",
    "                        except:\n",
    "                            diskonProduk=''\n",
    "                        try:\n",
    "                            hargaLama=item.find_all('div', {\"class\":\"detail-right\"})[0].text\n",
    "                            hargaLama=hargaLama.find_all('p')[0].text\n",
    "                            hargaLama = hargaLama.replace('IDR ','')\n",
    "                            hargaLama = hargaLama.replace('.','')\n",
    "                        except:\n",
    "                            hargaLama =\"\"\n",
    "                        try:\n",
    "                            hargaBaru= item.find_all('div', {\"class\":\"detail-right\"})[0].text\n",
    "                            hargaBaru=hargaBaru.find_all('p', {\"class\":\"detail-right\"})[0].text\n",
    "                            hargaBaru = hargaBaru.replace('IDR ','')\n",
    "                            hargaBaru = hargaBaru.replace('.','')\n",
    "                        except:\n",
    "                            hargaBaru= \"\"\n",
    "                        \n",
    "                        try:\n",
    "                            wil_url_produk=item.find_all('a')[0]\n",
    "                            linkProduk=wil_url_produk.get('href')\n",
    "                        except:\n",
    "                            linkProduk=''\n",
    "                        try:\n",
    "                            u= urlopen(linkProduk)\n",
    "                            url_produk_soup = BeautifulSoup(u, \"html.parser\")\n",
    "                            kat= url_produk_soup.find('div', {\"class\":\"detail-wrapper\"})\n",
    "                            kategori= kat.find_all('a')[0].text\n",
    "                            \n",
    "                        except:\n",
    "                            kategoriProduk= ''\n",
    "\n",
    "                        berrybenka=[linkEcommerce,kategori,namaProduk,hargaBaru,hargaLama,diskonProduk,linkProduk, datetime.now().strftime(\"%y-%m-%d %H:%M\")]\n",
    "                        berrybenka_list.append(berrybenka)\n",
    "            \n",
    "    import pandas as pd\n",
    "    import os\n",
    "    path = 'F:\\\\SKRIPSI\\\\Topik2\\\\UjianValidasi\\\\LinkURL\\\\Result5\\\\'\n",
    "    now = datetime.now()\n",
    "    filename = 'berrybenka_%s_%s_%s %s_%s_%s_%s.csv'%(now.day,now.month,now.year,now.hour,now.minute,now.second,now.microsecond)\n",
    "    df=pd.DataFrame(berrybenka_list, columns=['linkEcommerce','kategoriProduk','namaProduk','hargaBaru','hargaLama','diskonProduk','linkProduk','tgl update'])\n",
    "    df.to_csv(os.path.join(path, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
